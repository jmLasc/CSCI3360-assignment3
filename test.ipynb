{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from starlette.responses import FileResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate loading\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Define request and response models\n",
    "class QueryRequest(BaseModel):\n",
    "    prompt: str\n",
    "    headers: list\n",
    "    sample: list # can be entire csv, remember to process\n",
    "    \n",
    "class QueryResponse(BaseModel):\n",
    "    response: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper funcs\n",
    "def print_red(*strings):\n",
    "  print('\\033[91m' + ' '.join(strings) + '\\033[0m')\n",
    "\n",
    "# print msg in blue, , accept multiple strings like print statement\n",
    "def print_blue(*strings):\n",
    "  print('\\033[94m' + ' '.join(strings) + '\\033[0m')\n",
    "\n",
    "def sanitize_input(query: str) -> str:\n",
    "    \"\"\"Sanitize input to the python REPL.\n",
    "    Remove whitespace, backtick & python (if llm mistakes python console as terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # Removes `, whitespace & python from start\n",
    "    query = re.sub(r\"^(\\s|`)*(?i:python)?\\s*\", \"\", query)\n",
    "    # Removes whitespace & ` from end\n",
    "    query = re.sub(r\"(\\s|`)*$\", \"\", query)\n",
    "    return query\n",
    "    \n",
    "def execute_panda_dataframe_code(code):\n",
    "    \"\"\"\n",
    "    Execute the given python code and return the output. \n",
    "    References:\n",
    "    1. https://github.com/langchain-ai/langchain-experimental/blob/main/libs/experimental/langchain_experimental/utilities/python.py\n",
    "    2. https://github.com/langchain-ai/langchain-experimental/blob/main/libs/experimental/langchain_experimental/tools/python/tool.py\n",
    "    \"\"\"\n",
    "     # Save the current standard output to restore later\n",
    "    old_stdout = sys.stdout\n",
    "    # Redirect standard output to a StringIO object to capture any output generated by the code execution\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    try:\n",
    "\t\t    # Execute the provided code within the current environment\n",
    "        cleaned_command = sanitize_input(code)\n",
    "        exec(code)\n",
    "        \n",
    "        # Restore the original standard output after code execution\n",
    "        sys.stdout = old_stdout\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Return any captured output from the executed code\n",
    "        return mystdout.getvalue()\n",
    "    except Exception as e:\n",
    "        sys.stdout = old_stdout\n",
    "        return repr(e)\n",
    "\n",
    "def clean_spec(raw_text):\n",
    "  cleaned_text = re.sub(r'^```json\\n|\\n```$|\\\\n|\\\\|^```|\\n\\s*|\\r', '', raw_text)\n",
    "  formatted_json = cleaned_text.strip()\n",
    "  return formatted_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"strict\": True,\n",
    "            \"name\": \"generate_chart\",\n",
    "            \"description\": \"\"\"\n",
    "            ALways try to call this function.\n",
    "            Call this to generate a Vega-lite specification based on the user's inquiry for visualization. Requests can be short / terse and should relate to the data. Example user inquiries could be 'mpg over time' or 'cars by origins' if the csv is about cars.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The user's query. Can be re-written to be more comprehensible for Vega-lite generation, which will be handled by OpenAI.\",\n",
    "                    },\n",
    "                    \"context\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Relevant context that will be used in generating the Vega-Lite chart. Should include information such as headers, data sample, among any other facts that would be useful for chart generation.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\", \"context\"],\n",
    "                \"additionalProperties\": False,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\", \n",
    "        \"function\": {\n",
    "            \"strict\": True,\n",
    "            \"name\": \"analyze_data\",\n",
    "            \"description\": \"\"\"Call this to generate Python code that uses pandas for data analysis. The code should assist in understanding metrics or performing tasks such as summarizing data, finding correlations, handling missing values, etc. \n",
    "            Example user inquiries could be:\n",
    "            - 'summary statistics'\n",
    "            - 'correlation between X and Y'\n",
    "            - 'mean of X variable'. \n",
    "            \n",
    "            Should return the desired metrics as a string.\n",
    "            Should be ran multiple times in case you cannot generate all of the necessary metrics in one go or in the event that the code you ran failed.\n",
    "            Very important is that you must begin with \"global df\", so you can have access to the varaible df, which is a pandas df of the user's provided data.\n",
    "            \n",
    "            You may also run this code in the event that you need to peek at some metrics in order to more fully reply to the user.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"code\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The code to execute on a pandas df named 'df'. Must be written in Python and executable. Must end in a formatted print statement, e.g. print(f'[relevant info...]'), as its output will be captured by StringIO.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"code\"],\n",
    "                \"additionalProperties\": False,\n",
    "            }}\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"strict\": True,\n",
    "            \"name\": \"finalize_response\",\n",
    "            \"description\": \"\"\"\n",
    "            Call this after generating all of the needed information for an appropriate response. \n",
    "            If this tool is to be called, it should be the last tool called.\n",
    "\n",
    "            You can draw from information provided in the chat history and from the tool results.\n",
    "            \n",
    "            In rare cases, if the user's inquiry is irrelevant or not related to data analysis, you may provide a blank Vega-lite spec with a description field that explains why the user's query is not being processed.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"vega_spec\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The final Vega-lite spec (must be a JSON). Can be blank, but only when raising an error. \n",
    "                        Must have a descriptive 'description' field that talks about the data. If code was ran, it must summarize the metrics obtained.\n",
    "                        If the user is being rejected, please inform the function of that as well.\"\"\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"vega_spec\"],\n",
    "                \"additionalProperties\": False,\n",
    "        }}\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompts\n",
    "react_function_calling_prompt = '''You are a data analysis assistant using the ReAct style of reasoning for LLMs.\n",
    "\n",
    "You run in a loop of Thought, Action, Observation in the following manner to answer the user question.\n",
    "You MUST articulate your process in this structured manner:\n",
    "\n",
    "Question: the input query you must answer in full\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of tools provided\n",
    "Action Input: the input to the action\n",
    "\n",
    "\n",
    "You will be then call again with the result of the action.\n",
    "\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "'''\n",
    "\n",
    "vega_spec_prompt = ''' \n",
    "You are a data visualization assistant who will help the user with generating Vega-lite specifications.\n",
    "Respond to the user's question faithfully and to the best of your ability. \n",
    "\n",
    "Your main task is to generate a Vega-lite spec (json), which is to aid in visualization of the data.\n",
    "\n",
    "The user may ask for a scatterplot, bar chart, line chart, or any other visualization supported by Vega-lite. If the user does not specify, pick a visualization best compatible with the request and Vega-lite's limitations.\n",
    "When making a graph in this way, try not to use the names of the entries unless specifically asked to. For example, the user may provide a csv of book names and ask you to list out the sales of a certain series. In that case, do not list out every book in the csv, but rather target that series specifically to the best of your ability.\n",
    "\n",
    "You are to make very accurate predictions and realistic visualizations that are helpful and visually useful for the user.\n",
    "Your output is strictly in JSON format only. You will be rewarded for doing an accurate job.\n",
    "'''\n",
    "\n",
    "synthesis_prompt = '''\n",
    "Given the following chunk of text, you must now make a singular Vega-lite spec. It must be in JSON format. Your task is to merge the text outside of the JSON and alter the 'description' field of the final Vega-lite spec such that it has all of the relevant info to be communicated to the user. This description is less about the Vega-lite spec and more about communicating ideas about the data / answering the query to the user.\n",
    "\n",
    "If the user is being rejected, please make sure to still provide a valid Vega-lite spec and make it such that the description is informing the user that they are being rejected because their query was not related.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcs\n",
    "def create_vega_spec(query, context):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": vega_spec_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is the context to aid you in Vega-lite spec generation: {context}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"This is my inquiry for which you are to generate a Vega-lite spec in JSON: {query}\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create( # Chat\n",
    "            messages=messages,\n",
    "            model=\"gpt-4o\",\n",
    "            response_format= { \"type\": \"json_object\" }\n",
    "        )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def create_analysis_code(code):\n",
    "    sanitized = sanitize_input(code)\n",
    "    result = execute_panda_dataframe_code(sanitized)\n",
    "\n",
    "\n",
    "    return f\"\"\"\n",
    "    ** BEGIN PYTHON CODE RESULT **\n",
    "    {result}\n",
    "    ** END PYTHON CODE REUSLT ** \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def synthesize_final_ans(vega_spec):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": 'system',\n",
    "            \"content\": synthesis_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": 'user',\n",
    "            \"content\": str(vega_spec)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create( # Chat\n",
    "            messages=messages,\n",
    "            model=\"gpt-4o\",\n",
    "            response_format= { \"type\": \"json_object\" }\n",
    "        )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "df = pd.DataFrame() # Store outside of funcs for global scope. Make sure to use \"global\" in relevant funcs.\n",
    "\n",
    "tool_map = {\n",
    "    'generate_chart': create_vega_spec,\n",
    "    'analyze_data': create_analysis_code,\n",
    "    'finalize_response': synthesize_final_ans\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai(request: QueryRequest):\n",
    "    try:\n",
    "        global df\n",
    "        df = pd.DataFrame((request.sample)) # Catch df\n",
    "        to_json = None\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": react_function_calling_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here are the headers: {', '.join(request.headers)}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Here is a subsection of the csv to better contextualize your answers: {df.head(20)} \n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "\n",
    "                Your final Vega-Lite specification should at least have:\n",
    "                - A \"description\" field that summarizes what the specification is.\n",
    "                - The x-axis should be labeled.\n",
    "                - The y-axis should be labeled.\n",
    "                - Be in JSON format.\n",
    "                - No URL field.\n",
    "\n",
    "                Give me a Vega-Lite (JSON) specification that fulfills the following request: {request.prompt}\"\"\"\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        i = 0\n",
    "        while i < 10: # Max of 10 iters, change if needed\n",
    "            print(f\"current iter:{i}\")\n",
    "            response = client.chat.completions.create( # Chat\n",
    "                messages=messages,\n",
    "                model=\"gpt-4o\",\n",
    "                tools=tools\n",
    "            )\n",
    "\n",
    "            if response.choices[0].message.content:\n",
    "                print_red(response.choices[0].message.content) \n",
    "            \n",
    "            messages.append(response.choices[0].message)\n",
    "\n",
    "            if not response.choices[0].message.tool_calls:\n",
    "                break\n",
    "\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                print_blue('calling:'+tool_call.function.name)           \n",
    "                \n",
    "                # call the function\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                function_to_call = tool_map[tool_call.function.name]\n",
    "\n",
    "                result = function_to_call(**arguments) # save outcome\n",
    "\n",
    "                # create a message containing the tool call result\n",
    "                result_content = json.dumps({\n",
    "                    **arguments,\n",
    "                    \"result\": result\n",
    "                })\n",
    "                function_call_result_message = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": result_content,\n",
    "                    \"tool_call_id\": tool_call.id\n",
    "                }\n",
    "                print_blue('action result:' + result_content)\n",
    "\n",
    "                # save the action outcome for LLM\n",
    "                messages.append(function_call_result_message)\n",
    "            \n",
    "                # break\n",
    "                if tool_call.function.name == \"finalize_response\":\n",
    "                    print(\"Hey, I'm done!\")\n",
    "                    to_json = result\n",
    "                    i += 10\n",
    "                    break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        try:\n",
    "            response_json = json.loads(to_json)\n",
    "            return QueryResponse(response=response_json)\n",
    "        except json.JSONDecodeError:\n",
    "            raise HTTPException(status_code=500, detail=\"Failed to decode JSON from OpenAI response. Apologies, but please try again.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter:0\n",
      "\u001b[94mcalling:analyze_data\u001b[0m\n",
      "\u001b[94maction result:{\"code\": \"global df\\nmean_money = df['Money'].mean()\\nprint(f'Mean Money: {mean_money}')\", \"result\": \"\\n    ** BEGIN PYTHON CODE RESULT **\\n    TypeError(\\\"Could not convert string '123234733345987' to numeric\\\")\\n    ** END PYTHON CODE REUSLT ** \\n    \\n    \"}\u001b[0m\n",
      "\u001b[94mcalling:generate_chart\u001b[0m\n",
      "\u001b[94maction result:{\"query\": \"average money for each sex\", \"context\": \"Headers: Name, Money, Items in Cart, Sex; Data Sample: John, 123, 3, M; Jane, 234, 5, F; Alia, 733, 8, F; Bobb, 345, 9, M; Crom, 987, 3, M\", \"result\": \"\\n{\\n  \\\"$schema\\\": \\\"https://vega.github.io/schema/vega-lite/v5.json\\\",\\n  \\\"description\\\": \\\"Average money for each sex.\\\",\\n  \\\"data\\\": {\\n    \\\"values\\\": [\\n      {\\\"Name\\\": \\\"John\\\", \\\"Money\\\": 123, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Jane\\\", \\\"Money\\\": 234, \\\"Items in Cart\\\": 5, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Alia\\\", \\\"Money\\\": 733, \\\"Items in Cart\\\": 8, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Bobb\\\", \\\"Money\\\": 345, \\\"Items in Cart\\\": 9, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Crom\\\", \\\"Money\\\": 987, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"}\\n    ]\\n  },\\n  \\\"mark\\\": \\\"bar\\\",\\n  \\\"encoding\\\": {\\n    \\\"x\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Sex\\\"}\\n    },\\n    \\\"y\\\": {\\n      \\\"aggregate\\\": \\\"mean\\\",\\n      \\\"field\\\": \\\"Money\\\",\\n      \\\"type\\\": \\\"quantitative\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Average Money\\\"}\\n    },\\n    \\\"color\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"legend\\\": null\\n    }\\n  }\\n}\"}\u001b[0m\n",
      "current iter:1\n",
      "\u001b[94mcalling:analyze_data\u001b[0m\n",
      "\u001b[94maction result:{\"code\": \"global df\\ndf['Money'] = pd.to_numeric(df['Money'], errors='coerce')\\nmean_money = df['Money'].mean()\\nprint(f'Mean Money: {mean_money}')\", \"result\": \"\\n    ** BEGIN PYTHON CODE RESULT **\\n    Mean Money: 484.4\\n\\n    ** END PYTHON CODE REUSLT ** \\n    \\n    \"}\u001b[0m\n",
      "current iter:2\n",
      "\u001b[94mcalling:finalize_response\u001b[0m\n",
      "\u001b[94maction result:{\"vega_spec\": \"{\\n  \\\"$schema\\\": \\\"https://vega.github.io/schema/vega-lite/v5.json\\\",\\n  \\\"description\\\": \\\"Average money for each sex, with a calculated mean money value of 484.4.\\\",\\n  \\\"data\\\": {\\n    \\\"values\\\": [\\n      {\\\"Name\\\": \\\"John\\\", \\\"Money\\\": 123, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Jane\\\", \\\"Money\\\": 234, \\\"Items in Cart\\\": 5, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Alia\\\", \\\"Money\\\": 733, \\\"Items in Cart\\\": 8, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Bobb\\\", \\\"Money\\\": 345, \\\"Items in Cart\\\": 9, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Crom\\\", \\\"Money\\\": 987, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"}\\n    ]\\n  },\\n  \\\"mark\\\": \\\"bar\\\",\\n  \\\"encoding\\\": {\\n    \\\"x\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Sex\\\"}\\n    },\\n    \\\"y\\\": {\\n      \\\"aggregate\\\": \\\"mean\\\",\\n      \\\"field\\\": \\\"Money\\\",\\n      \\\"type\\\": \\\"quantitative\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Average Money\\\"}\\n    },\\n    \\\"color\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"legend\\\": null\\n    }\\n  }\\n}\", \"result\": \"{\\n  \\\"$schema\\\": \\\"https://vega.github.io/schema/vega-lite/v5.json\\\",\\n  \\\"description\\\": \\\"This bar chart represents the average amount of money for each sex in the dataset. The calculated mean money value across all entries is 484.4, which provides insight into spending behavior as categorized by gender. Individuals are categorized as either male or female, showcasing the disparity, if any, between the two groups. It also considers the total number of items in the cart alongside the monetary value per transaction.\\\",\\n  \\\"data\\\": {\\n    \\\"values\\\": [\\n      {\\\"Name\\\": \\\"John\\\", \\\"Money\\\": 123, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Jane\\\", \\\"Money\\\": 234, \\\"Items in Cart\\\": 5, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Alia\\\", \\\"Money\\\": 733, \\\"Items in Cart\\\": 8, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Bobb\\\", \\\"Money\\\": 345, \\\"Items in Cart\\\": 9, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Crom\\\", \\\"Money\\\": 987, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"}\\n    ]\\n  },\\n  \\\"mark\\\": \\\"bar\\\",\\n  \\\"encoding\\\": {\\n    \\\"x\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Sex\\\"}\\n    },\\n    \\\"y\\\": {\\n      \\\"aggregate\\\": \\\"mean\\\",\\n      \\\"field\\\": \\\"Money\\\",\\n      \\\"type\\\": \\\"quantitative\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Average Money\\\"}\\n    },\\n    \\\"color\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"legend\\\": null\\n    }\\n  }\\n}\"}\u001b[0m\n",
      "Hey, I'm done!\n"
     ]
    }
   ],
   "source": [
    "# dummy\n",
    "# Create sample data for testing\n",
    "test_headers = [\"Name\", \"Money\", \"Items in Cart\", \"Sex\"]\n",
    "test_sample = [\n",
    "    {\"Name\": \"John\", \"Money\": \"123\", \"Items in Cart\": \"3\", \"Sex\":\"M\"},\n",
    "    {\"Name\": \"Jane\", \"Money\": \"234\", \"Items in Cart\": \"5\", \"Sex\":\"F\"},\n",
    "    {\"Name\": \"Alia\", \"Money\": \"733\", \"Items in Cart\": \"8\", \"Sex\":\"F\"},\n",
    "    {\"Name\": \"Bobb\", \"Money\": \"345\", \"Items in Cart\": \"9\", \"Sex\":\"M\"},\n",
    "    {\"Name\": \"Crom\", \"Money\": \"987\", \"Items in Cart\": \"3\", \"Sex\":\"M\"},\n",
    "]\n",
    "\n",
    "# Create a QueryRequest object for testing\n",
    "test_query_request = QueryRequest(\n",
    "    prompt=\"avg money for each sex, tell me the mean money as well\",\n",
    "    headers=test_headers,\n",
    "    sample=test_sample\n",
    ")\n",
    "\n",
    "end = query_openai(test_query_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$schema': 'https://vega.github.io/schema/vega-lite/v5.json',\n",
       " 'description': 'This bar chart represents the average amount of money for each sex in the dataset. The calculated mean money value across all entries is 484.4, which provides insight into spending behavior as categorized by gender. Individuals are categorized as either male or female, showcasing the disparity, if any, between the two groups. It also considers the total number of items in the cart alongside the monetary value per transaction.',\n",
       " 'data': {'values': [{'Name': 'John',\n",
       "    'Money': 123,\n",
       "    'Items in Cart': 3,\n",
       "    'Sex': 'M'},\n",
       "   {'Name': 'Jane', 'Money': 234, 'Items in Cart': 5, 'Sex': 'F'},\n",
       "   {'Name': 'Alia', 'Money': 733, 'Items in Cart': 8, 'Sex': 'F'},\n",
       "   {'Name': 'Bobb', 'Money': 345, 'Items in Cart': 9, 'Sex': 'M'},\n",
       "   {'Name': 'Crom', 'Money': 987, 'Items in Cart': 3, 'Sex': 'M'}]},\n",
       " 'mark': 'bar',\n",
       " 'encoding': {'x': {'field': 'Sex',\n",
       "   'type': 'nominal',\n",
       "   'axis': {'title': 'Sex'}},\n",
       "  'y': {'aggregate': 'mean',\n",
       "   'field': 'Money',\n",
       "   'type': 'quantitative',\n",
       "   'axis': {'title': 'Average Money'}},\n",
       "  'color': {'field': 'Sex', 'type': 'nominal', 'legend': None}}}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
