{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from starlette.responses import FileResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate loading\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Define request and response models\n",
    "class QueryRequest(BaseModel):\n",
    "    prompt: str\n",
    "    headers: list\n",
    "    sample: list # can be entire csv, remember to process\n",
    "    \n",
    "class QueryResponse(BaseModel):\n",
    "    response: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided helper funcs\n",
    "def print_red(*strings):\n",
    "  print('\\033[91m' + ' '.join(strings) + '\\033[0m')\n",
    "\n",
    "# print msg in blue, , accept multiple strings like print statement\n",
    "def print_blue(*strings):\n",
    "  print('\\033[94m' + ' '.join(strings) + '\\033[0m')\n",
    "\n",
    "def sanitize_input(query: str) -> str:\n",
    "    \"\"\"Sanitize input to the python REPL.\n",
    "    Remove whitespace, backtick & python (if llm mistakes python console as terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # Removes `, whitespace & python from start\n",
    "    query = re.sub(r\"^(\\s|`)*(?i:python)?\\s*\", \"\", query)\n",
    "    # Removes whitespace & ` from end\n",
    "    query = re.sub(r\"(\\s|`)*$\", \"\", query)\n",
    "    return query\n",
    "    \n",
    "def execute_panda_dataframe_code(code):\n",
    "    \"\"\"\n",
    "    Execute the given python code and return the output. \n",
    "    References:\n",
    "    1. https://github.com/langchain-ai/langchain-experimental/blob/main/libs/experimental/langchain_experimental/utilities/python.py\n",
    "    2. https://github.com/langchain-ai/langchain-experimental/blob/main/libs/experimental/langchain_experimental/tools/python/tool.py\n",
    "    \"\"\"\n",
    "     # Save the current standard output to restore later\n",
    "    old_stdout = sys.stdout\n",
    "    # Redirect standard output to a StringIO object to capture any output generated by the code execution\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    try:\n",
    "\t\t    # Execute the provided code within the current environment\n",
    "        cleaned_command = sanitize_input(code)\n",
    "        exec(code)\n",
    "        \n",
    "        # Restore the original standard output after code execution\n",
    "        sys.stdout = old_stdout\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Return any captured output from the executed code\n",
    "        return mystdout.getvalue()\n",
    "    except Exception as e:\n",
    "        sys.stdout = old_stdout\n",
    "        return repr(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_chart\",\n",
    "            \"description\": \"\"\"\n",
    "            ALways try to call this function.\n",
    "            Call this to generate a Vega-lite specification based on the user's inquiry for visualization. Requests can be short / terse and should relate to the data. Example user inquiries could be 'mpg over time' or 'cars by origins' if the csv is about cars.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The user's query. Can be re-written to be more comprehensible for Vega-lite generation, which will be handled by OpenAI.\",\n",
    "                    },\n",
    "                    \"context\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Relevant context that will be used in generating the Vega-Lite chart. Should include information such as headers, data sample, among any other facts that would be useful for chart generation.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\", \"context\"],  \n",
    "                \"additionalProperties\": False,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\", \n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_data\",\n",
    "            \"description\": \"\"\"Call this to generate Python code that uses pandas for data analysis. The code should assist in understanding metrics or performing tasks such as summarizing data, finding correlations, handling missing values, etc. Example user inquiries could be 'show summary statistics for all columns', 'find correlation between age and salary', or 'find a mean of prices in the dataset'. Should return the desired metrics as a string.\n",
    "            \n",
    "            May be ran multiple times in case you cannot generate all of the necessary metrics in one go or in the event that the code you ran failed.\n",
    "            Very important is that you must begin with \"global df\", so you can have access to the varaible df, which is a pandas df of the user's provided data.\n",
    "            You may also run this code in the event that you need to peek at some metrics in order to more fully reply to the user.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"code\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The code to execute on a pandas df named 'df'. Must be written in Python and executable. Must end in a formatted print statement, e.g. print(f'[relevant info...]'), as its output will be captured by StringIO.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"code\"],\n",
    "                \"additionalProperties\": False\n",
    "            }}\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"finalize_response\",\n",
    "            \"description\": \"\"\"\n",
    "            Call this after generating all of the needed information for an appropriate response. \n",
    "            If this tool is to be called, it should be the last tool called as it ends the chain-of-thought and synthesizes what has been generated so far.\n",
    "\n",
    "            If the user inquiry is irrelevant, provide an empty spec and a description that informs the user that their inquiry is irrelevant and suggest potential questions to ask.\n",
    "            Possible scenarios for raising an error include:\n",
    "            - The question is unanswerable or irrelevant to the data.\n",
    "            - The visualization is impossible to perform.\n",
    "            - The Vega-Lite (JSON) specification is ill-formed and cannot be fixed.\n",
    "            - The message is unrelated to the data being given.\n",
    "            \n",
    "            A Vega-lite spec (JSON-like) must be provided.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"strict\": True,\n",
    "                \"properties\": {\n",
    "                    \"spec\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"The final Vega-lite spec (must be a JSON) for data visualization (if possible). Can be blank, but only when raising an error. Must have a 'description' field.\"\n",
    "                    },\n",
    "                    \"desc\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The final response to give to the user. May include information about the metrics.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"spec\", \"desc\"],\n",
    "        }}\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "react_function_calling_prompt = '''You are a data analysis assistant using the ReAct style of reasoning for LLMs.\n",
    "\n",
    "You run in a loop of Thought, Action, Observation in the following manner to answer the user question.\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of tools provided\n",
    "Action Input: the input to the action\n",
    "\n",
    "You will be then call again with the result of the action.\n",
    "\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "'''\n",
    "\n",
    "vega_spec_prompt = ''' \n",
    "You are a data visualization assistant who will help the user with generating Vega-lite specifications.\n",
    "Respond to the user's question faithfully and to the best of your ability. \n",
    "\n",
    "Your main task is to generate a Vega-lite spec (json), which is to aid in visualization of the data.\n",
    "\n",
    "The user may ask for a scatterplot, bar chart, line chart, or any other visualization supported by Vega-lite. If the user does not specify, pick a visualization best compatible with the request and Vega-lite's limitations.\n",
    "When making a graph in this way, try not to use the names of the entries unless specifically asked to. For example, the user may provide a csv of book names and ask you to list out the sales of a certain series. In that case, do not list out every book in the csv, but rather target that series specifically to the best of your ability.\n",
    "\n",
    "You are to make very accurate predictions and realistic visualizations that are helpful and visually useful for the user.\n",
    "Your output is strictly in JSON format only. You will be rewarded for doing an accurate job.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs\n",
    "def create_vega_spec(query, context):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": vega_spec_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is the context to aid you in Vega-lite spec generation: {context}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"This is my inquiry for which you are to generate a Vega-lite spec in JSON: {query}\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create( # Chat\n",
    "            messages=messages,\n",
    "            model=\"gpt-4o\"\n",
    "        )\n",
    "\n",
    "\n",
    "    return f\"\"\"\n",
    "    ** BEGIN VEGA SPEC **\n",
    "    {response.choices[0].message.content}\n",
    "    ** END VEGA SPEC  **\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def create_analysis_code(code):\n",
    "    sanitized = sanitize_input(code)\n",
    "    result = execute_panda_dataframe_code(sanitized)\n",
    "\n",
    "\n",
    "    return f\"\"\"\n",
    "    ** BEGIN PYTHON CODE RESULT **\n",
    "    {result}\n",
    "    ** END PYTHON CODE REUSLT ** \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def synthesize_final_ans(spec, desc):\n",
    "    spec['description'] = desc\n",
    "    return str(spec)\n",
    "\n",
    "df = pd.DataFrame() # Store outside of funcs for global scope. Make sure to use \"global\" in relevant funcs.\n",
    "\n",
    "tool_map = {\n",
    "    'generate_chart': create_vega_spec,\n",
    "    'analyze_data': create_analysis_code,\n",
    "    'finalize_response': synthesize_final_ans\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai(request: QueryRequest):\n",
    "\n",
    "    global df\n",
    "    df = pd.DataFrame((request.sample)) # Catch df\n",
    "\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": react_function_calling_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here are the headers: {', '.join(request.headers)}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Here is a subsection of the csv to better contextualize your answers: {df.head(20)} \n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "\n",
    "            Your final Vega-Lite specification should at least have:\n",
    "            - A \"description\" field that summarizes what the specification is.\n",
    "            - The x-axis should be labeled.\n",
    "            - The y-axis should be labeled.\n",
    "            - Be in JSON format.\n",
    "            - No URL field.\n",
    "\n",
    "            Give me a Vega-Lite (JSON) specification that fulfills the following request: {request.prompt}\"\"\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    i = 0\n",
    "    while i < 10: # Max of 8 iterations, change if needed\n",
    "        response = client.chat.completions.create( # Chat\n",
    "            messages=messages,\n",
    "            model=\"gpt-4o\",\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        if response.choices[0].message.content:\n",
    "            print_red(response.choices[0].message.content) \n",
    "        \n",
    "        messages.append(response.choices[0].message)\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            print_blue('calling:'+tool_call.function.name)            \n",
    "            \n",
    "            # call the function\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            function_to_call = tool_map[tool_call.function.name]\n",
    "\n",
    "            result = function_to_call(**arguments) # save outcome\n",
    "\n",
    "            # create a message containing the tool call result\n",
    "            result_content = json.dumps({\n",
    "                **arguments,\n",
    "                \"result\": result\n",
    "            })\n",
    "            function_call_result_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": result_content,\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            }\n",
    "            print_blue('action result:' + result_content)\n",
    "\n",
    "            # save the action outcome for LLM\n",
    "            messages.append(function_call_result_message)\n",
    "            \n",
    "            # Finishing response, loop ends \n",
    "            if tool_call.function.name == 'finalize_response':\n",
    "                i += 8\n",
    "                break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return(messages)\n",
    "\n",
    "        # response_json = json.loads(response.choices[0].message.content.strip())\n",
    "        # return QueryResponse(response=response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mcalling:generate_chart\u001b[0m\n",
      "\u001b[94maction result:{\"query\": \"money by sex\", \"context\": \"Headers: Name, Money, Items in Cart, Sex. Sample data: John 123 3 M, Jane 234 5 F, Alia 733 8 F, Bobb 345 9 M, Crom 987 3 M.\", \"result\": \"\\n    ** BEGIN VEGA SPEC **\\n    ```json\\n{\\n  \\\"$schema\\\": \\\"https://vega.github.io/schema/vega-lite/v5.json\\\",\\n  \\\"description\\\": \\\"A bar chart showing total money by sex.\\\",\\n  \\\"data\\\": {\\n    \\\"values\\\": [\\n      {\\\"Name\\\": \\\"John\\\", \\\"Money\\\": 123, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Jane\\\", \\\"Money\\\": 234, \\\"Items in Cart\\\": 5, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Alia\\\", \\\"Money\\\": 733, \\\"Items in Cart\\\": 8, \\\"Sex\\\": \\\"F\\\"},\\n      {\\\"Name\\\": \\\"Bobb\\\", \\\"Money\\\": 345, \\\"Items in Cart\\\": 9, \\\"Sex\\\": \\\"M\\\"},\\n      {\\\"Name\\\": \\\"Crom\\\", \\\"Money\\\": 987, \\\"Items in Cart\\\": 3, \\\"Sex\\\": \\\"M\\\"}\\n    ]\\n  },\\n  \\\"mark\\\": \\\"bar\\\",\\n  \\\"encoding\\\": {\\n    \\\"x\\\": {\\n      \\\"field\\\": \\\"Sex\\\",\\n      \\\"type\\\": \\\"nominal\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Sex\\\"}\\n    },\\n    \\\"y\\\": {\\n      \\\"aggregate\\\": \\\"sum\\\",\\n      \\\"field\\\": \\\"Money\\\",\\n      \\\"type\\\": \\\"quantitative\\\",\\n      \\\"axis\\\": {\\\"title\\\": \\\"Total Money\\\"}\\n    }\\n  }\\n}\\n```\\n    ** END VEGA SPEC  **\\n    \\n    \"}\u001b[0m\n",
      "\u001b[94mcalling:finalize_response\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "synthesize_final_ans() missing 1 required positional argument: 'spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 20\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create a QueryRequest object for testing\u001b[39;00m\n\u001b[0;32m     14\u001b[0m test_query_request \u001b[38;5;241m=\u001b[39m QueryRequest(\n\u001b[0;32m     15\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoney and sex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     headers\u001b[38;5;241m=\u001b[39mtest_headers,\n\u001b[0;32m     17\u001b[0m     sample\u001b[38;5;241m=\u001b[39mtest_sample\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mquery_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_query_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[167], line 54\u001b[0m, in \u001b[0;36mquery_openai\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m     51\u001b[0m arguments \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments)\n\u001b[0;32m     52\u001b[0m function_to_call \u001b[38;5;241m=\u001b[39m tool_map[tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m---> 54\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_to_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# save outcome\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# create a message containing the tool call result\u001b[39;00m\n\u001b[0;32m     57\u001b[0m result_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments,\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\n\u001b[0;32m     60\u001b[0m })\n",
      "\u001b[1;31mTypeError\u001b[0m: synthesize_final_ans() missing 1 required positional argument: 'spec'"
     ]
    }
   ],
   "source": [
    "# dummy\n",
    "# Create sample data for testing\n",
    "test_headers = [\"Name\", \"Money\", \"Items in Cart\", \"Sex\"]\n",
    "test_sample = [\n",
    "    {\"Name\": \"John\", \"Money\": \"123\", \"Items in Cart\": \"3\", \"Sex\":\"M\"},\n",
    "    {\"Name\": \"Jane\", \"Money\": \"234\", \"Items in Cart\": \"5\", \"Sex\":\"F\"},\n",
    "    {\"Name\": \"Alia\", \"Money\": \"733\", \"Items in Cart\": \"8\", \"Sex\":\"F\"},\n",
    "    {\"Name\": \"Bobb\", \"Money\": \"345\", \"Items in Cart\": \"9\", \"Sex\":\"M\"},\n",
    "    {\"Name\": \"Crom\", \"Money\": \"987\", \"Items in Cart\": \"3\", \"Sex\":\"M\"},\n",
    "    # Add more rows as needed\n",
    "]\n",
    "\n",
    "# Create a QueryRequest object for testing\n",
    "test_query_request = QueryRequest(\n",
    "    prompt=\"money and sex\",\n",
    "    headers=test_headers,\n",
    "    sample=test_sample\n",
    ")\n",
    "\n",
    "r = query_openai(test_query_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
